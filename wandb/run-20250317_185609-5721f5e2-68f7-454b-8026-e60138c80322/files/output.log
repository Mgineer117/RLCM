[36;1mSaving config:
[0m
{
    "K_epochs":	5,
    "action_dim":	2,
    "actor_dim":	[
        64,
        64
    ],
    "actor_lr":	0.0003,
    "algo_name":	"ppo",
    "critic_dim":	[
        128,
        128
    ],
    "critic_lr":	0.0005,
    "device":	"cuda:0",
    "entropy_scaler":	0.001,
    "episode_len":	200,
    "eps":	0.2,
    "eval_episodes":	10,
    "eval_num":	10,
    "gae":	0.95,
    "gamma":	0.99,
    "gpu_idx":	0,
    "group":	"03-17_18-56-08.704367-a3c8",
    "load_pretrained_model":	false,
    "log_intervals":	10,
    "logdir":	"log/train_log/03-17_18-56-08.704367-a3c8",
    "minibatch_size":	512,
    "name":	"ppo-car-a3c8-seed:1825",
    "num_minibatch":	10,
    "num_runs":	10,
    "project":	"Exp",
    "seed":	1825,
    "state_dim":	4,
    "target_kl":	0.02,
    "task":	"car",
    "timesteps":	100000.0,
    "use_cuda":	true
}
PPO Training (Timesteps):   3%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                                                                                                                                                                                                                                                   | 2560/100000.0 [00:00<00:33, 2909.24it/s]
Traceback (most recent call last):
  File "/home/minjae/research/RLCM/main.py", line 196, in <module>
    run(args, seed, unique_id, exp_time)
  File "/home/minjae/research/RLCM/main.py", line 176, in run
    trainer.train()
  File "/home/minjae/research/RLCM/trainer/online_trainer.py", line 66, in train
    batch, sample_time = self.sampler.collect_samples(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/minjae/research/RLCM/utils/sampler.py", line 158, in collect_samples
    memory = self.collect_trajectory(
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/minjae/research/RLCM/utils/sampler.py", line 234, in collect_trajectory
    data = self.get_reset_data(batch_size=self.thread_batch_size)  # allocate memory
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/minjae/research/RLCM/utils/sampler.py", line 31, in get_reset_data
    terminals=np.full((batch_size, 1), np.nan, dtype=np.float32),
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/minjae/miniconda3/envs/rlcm/lib/python3.12/site-packages/numpy/_core/numeric.py", line 353, in full
    multiarray.copyto(a, fill_value, casting='unsafe')
KeyboardInterrupt
Exception ignored in atexit callback: <function _start_and_connect_service.<locals>.teardown_atexit at 0x7ee16444b2e0>
Traceback (most recent call last):
  File "/home/minjae/miniconda3/envs/rlcm/lib/python3.12/site-packages/wandb/sdk/lib/service_connection.py", line 94, in teardown_atexit
    conn.teardown(hooks.exit_code)
  File "/home/minjae/miniconda3/envs/rlcm/lib/python3.12/site-packages/wandb/sdk/lib/service_connection.py", line 226, in teardown
    self._router.join()
  File "/home/minjae/miniconda3/envs/rlcm/lib/python3.12/site-packages/wandb/sdk/interface/router.py", line 75, in join
    self._thread.join()
  File "/home/minjae/miniconda3/envs/rlcm/lib/python3.12/threading.py", line 1149, in join
    self._wait_for_tstate_lock()
  File "/home/minjae/miniconda3/envs/rlcm/lib/python3.12/threading.py", line 1169, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt:
