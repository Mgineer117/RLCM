[36;1mSaving config:
[0m
{
    "K_epochs":	5,
    "action_dim":	2,
    "actor_dim":	[
        64,
        64
    ],
    "actor_lr":	0.001,
    "algo_name":	"ppo",
    "critic_dim":	[
        128,
        128
    ],
    "critic_lr":	0.001,
    "device":	"cuda:0",
    "entropy_scaler":	0.001,
    "episode_len":	200,
    "eps":	0.2,
    "eval_episodes":	10,
    "eval_num":	10,
    "gae":	0.95,
    "gamma":	0.99,
    "gpu_idx":	0,
    "group":	"03-17_18-07-09.837326-1769",
    "load_pretrained_model":	false,
    "log_intervals":	10,
    "logdir":	"log/train_log/03-17_18-07-09.837326-1769",
    "minibatch_size":	128,
    "name":	"ppo-car-1769-seed:1825",
    "num_minibatch":	10,
    "num_runs":	10,
    "project":	"Exp",
    "seed":	1825,
    "state_dim":	4,
    "target_kl":	0.02,
    "task":	"car",
    "timesteps":	15,
    "use_cuda":	true
}
PPO Training (Timesteps): 2560it [00:01, 1623.93it/s]                                                                                                                                                                                                                                                                                                                                               
[32;1mtotal PPO training time: 0.00 hours[0m
============================================================================================
Device set to : NVIDIA GeForce RTX 4080 SUPER
============================================================================================
====================
Sampling Parameters:
====================
Cores (usage)/(given)     : [2]/30 out of 32
Total number of Worker  : 2
Max. batch size         : 1424
[36;1mSaving config:
[0m
{
    "K_epochs":	5,
    "action_dim":	2,
    "actor_dim":	[
        64,
        64
    ],
    "actor_lr":	0.001,
    "algo_name":	"ppo",
    "critic_dim":	[
        128,
        128
    ],
    "critic_lr":	0.001,
    "device":	"cuda:0",
    "entropy_scaler":	0.001,
    "episode_len":	200,
    "eps":	0.2,
    "eval_episodes":	10,
    "eval_num":	10,
    "gae":	0.95,
    "gamma":	0.99,
    "gpu_idx":	0,
    "group":	"03-17_18-07-09.837326-1769",
    "load_pretrained_model":	false,
    "log_intervals":	10,
    "logdir":	"log/train_log/03-17_18-07-09.837326-1769",
    "minibatch_size":	128,
    "name":	"ppo-car-1769-seed:410",
    "num_minibatch":	10,
    "num_runs":	10,
    "project":	"Exp",
    "seed":	410,
    "state_dim":	4,
    "target_kl":	0.02,
    "task":	"car",
    "timesteps":	15,
    "use_cuda":	true
}
PPO Training (Timesteps): 2560it [00:01, 1840.58it/s]                                                                                                                                                                                                                                                                                                                                               
[32;1mtotal PPO training time: 0.00 hours[0m
============================================================================================
Device set to : NVIDIA GeForce RTX 4080 SUPER
============================================================================================
====================
Sampling Parameters:
====================
Cores (usage)/(given)     : [2]/30 out of 32
Total number of Worker  : 2
Max. batch size         : 1424
[36;1mSaving config:
[0m
{
    "K_epochs":	5,
    "action_dim":	2,
    "actor_dim":	[
        64,
        64
    ],
    "actor_lr":	0.001,
    "algo_name":	"ppo",
    "critic_dim":	[
        128,
        128
    ],
    "critic_lr":	0.001,
    "device":	"cuda:0",
    "entropy_scaler":	0.001,
    "episode_len":	200,
    "eps":	0.2,
    "eval_episodes":	10,
    "eval_num":	10,
    "gae":	0.95,
    "gamma":	0.99,
    "gpu_idx":	0,
    "group":	"03-17_18-07-09.837326-1769",
    "load_pretrained_model":	false,
    "log_intervals":	10,
    "logdir":	"log/train_log/03-17_18-07-09.837326-1769",
    "minibatch_size":	128,
    "name":	"ppo-car-1769-seed:4507",
    "num_minibatch":	10,
    "num_runs":	10,
    "project":	"Exp",
    "seed":	4507,
    "state_dim":	4,
    "target_kl":	0.02,
    "task":	"car",
    "timesteps":	15,
    "use_cuda":	true
}
PPO Training (Timesteps): 2560it [00:01, 1912.52it/s]                                                                                                                                                                                                                                                                                                                                               
[32;1mtotal PPO training time: 0.00 hours[0m
============================================================================================
Device set to : NVIDIA GeForce RTX 4080 SUPER
============================================================================================
====================
Sampling Parameters:
====================
Cores (usage)/(given)     : [2]/30 out of 32
Total number of Worker  : 2
Max. batch size         : 1424
[36;1mSaving config:
[0m
{
    "K_epochs":	5,
    "action_dim":	2,
    "actor_dim":	[
        64,
        64
    ],
    "actor_lr":	0.001,
    "algo_name":	"ppo",
    "critic_dim":	[
        128,
        128
    ],
    "critic_lr":	0.001,
    "device":	"cuda:0",
    "entropy_scaler":	0.001,
    "episode_len":	200,
    "eps":	0.2,
    "eval_episodes":	10,
    "eval_num":	10,
    "gae":	0.95,
    "gamma":	0.99,
    "gpu_idx":	0,
    "group":	"03-17_18-07-09.837326-1769",
    "load_pretrained_model":	false,
    "log_intervals":	10,
    "logdir":	"log/train_log/03-17_18-07-09.837326-1769",
    "minibatch_size":	128,
    "name":	"ppo-car-1769-seed:4013",
    "num_minibatch":	10,
    "num_runs":	10,
    "project":	"Exp",
    "seed":	4013,
    "state_dim":	4,
    "target_kl":	0.02,
    "task":	"car",
    "timesteps":	15,
    "use_cuda":	true
}
PPO Training (Timesteps): 2560it [00:01, 1894.36it/s]                                                                                                                                                                                                                                                                                                                                               
[32;1mtotal PPO training time: 0.00 hours[0m
============================================================================================
Device set to : NVIDIA GeForce RTX 4080 SUPER
============================================================================================
====================
Sampling Parameters:
====================
Cores (usage)/(given)     : [2]/30 out of 32
Total number of Worker  : 2
Max. batch size         : 1424
[36;1mSaving config:
[0m
{
    "K_epochs":	5,
    "action_dim":	2,
    "actor_dim":	[
        64,
        64
    ],
    "actor_lr":	0.001,
    "algo_name":	"ppo",
    "critic_dim":	[
        128,
        128
    ],
    "critic_lr":	0.001,
    "device":	"cuda:0",
    "entropy_scaler":	0.001,
    "episode_len":	200,
    "eps":	0.2,
    "eval_episodes":	10,
    "eval_num":	10,
    "gae":	0.95,
    "gamma":	0.99,
    "gpu_idx":	0,
    "group":	"03-17_18-07-09.837326-1769",
    "load_pretrained_model":	false,
    "log_intervals":	10,
    "logdir":	"log/train_log/03-17_18-07-09.837326-1769",
    "minibatch_size":	128,
    "name":	"ppo-car-1769-seed:3658",
    "num_minibatch":	10,
    "num_runs":	10,
    "project":	"Exp",
    "seed":	3658,
    "state_dim":	4,
    "target_kl":	0.02,
    "task":	"car",
    "timesteps":	15,
    "use_cuda":	true
}
PPO Training (Timesteps): 2560it [00:01, 1760.73it/s]                                                                                                                                                                                                                                                                                                                                               
[32;1mtotal PPO training time: 0.00 hours[0m
============================================================================================
Device set to : NVIDIA GeForce RTX 4080 SUPER
============================================================================================
====================
Sampling Parameters:
====================
Cores (usage)/(given)     : [2]/30 out of 32
Total number of Worker  : 2
Max. batch size         : 1424
[36;1mSaving config:
[0m
{
    "K_epochs":	5,
    "action_dim":	2,
    "actor_dim":	[
        64,
        64
    ],
    "actor_lr":	0.001,
    "algo_name":	"ppo",
    "critic_dim":	[
        128,
        128
    ],
    "critic_lr":	0.001,
    "device":	"cuda:0",
    "entropy_scaler":	0.001,
    "episode_len":	200,
    "eps":	0.2,
    "eval_episodes":	10,
    "eval_num":	10,
    "gae":	0.95,
    "gamma":	0.99,
    "gpu_idx":	0,
    "group":	"03-17_18-07-09.837326-1769",
    "load_pretrained_model":	false,
    "log_intervals":	10,
    "logdir":	"log/train_log/03-17_18-07-09.837326-1769",
    "minibatch_size":	128,
    "name":	"ppo-car-1769-seed:2287",
    "num_minibatch":	10,
    "num_runs":	10,
    "project":	"Exp",
    "seed":	2287,
    "state_dim":	4,
    "target_kl":	0.02,
    "task":	"car",
    "timesteps":	15,
    "use_cuda":	true
}
PPO Training (Timesteps): 2560it [00:01, 1798.15it/s]                                                                                                                                                                                                                                                                                                                                               
[32;1mtotal PPO training time: 0.00 hours[0m
============================================================================================
Device set to : NVIDIA GeForce RTX 4080 SUPER
============================================================================================
====================
Sampling Parameters:
====================
Cores (usage)/(given)     : [2]/30 out of 32
Total number of Worker  : 2
Max. batch size         : 1424
[36;1mSaving config:
[0m
{
    "K_epochs":	5,
    "action_dim":	2,
    "actor_dim":	[
        64,
        64
    ],
    "actor_lr":	0.001,
    "algo_name":	"ppo",
    "critic_dim":	[
        128,
        128
    ],
    "critic_lr":	0.001,
    "device":	"cuda:0",
    "entropy_scaler":	0.001,
    "episode_len":	200,
    "eps":	0.2,
    "eval_episodes":	10,
    "eval_num":	10,
    "gae":	0.95,
    "gamma":	0.99,
    "gpu_idx":	0,
    "group":	"03-17_18-07-09.837326-1769",
    "load_pretrained_model":	false,
    "log_intervals":	10,
    "logdir":	"log/train_log/03-17_18-07-09.837326-1769",
    "minibatch_size":	128,
    "name":	"ppo-car-1769-seed:1680",
    "num_minibatch":	10,
    "num_runs":	10,
    "project":	"Exp",
    "seed":	1680,
    "state_dim":	4,
    "target_kl":	0.02,
    "task":	"car",
    "timesteps":	15,
    "use_cuda":	true
}
PPO Training (Timesteps): 2560it [00:01, 1756.46it/s]                                                                                                                                                                                                                                                                                                                                               
[32;1mtotal PPO training time: 0.00 hours[0m
============================================================================================
Device set to : NVIDIA GeForce RTX 4080 SUPER
============================================================================================
====================
Sampling Parameters:
====================
Cores (usage)/(given)     : [2]/30 out of 32
Total number of Worker  : 2
Max. batch size         : 1424
[36;1mSaving config:
[0m
{
    "K_epochs":	5,
    "action_dim":	2,
    "actor_dim":	[
        64,
        64
    ],
    "actor_lr":	0.001,
    "algo_name":	"ppo",
    "critic_dim":	[
        128,
        128
    ],
    "critic_lr":	0.001,
    "device":	"cuda:0",
    "entropy_scaler":	0.001,
    "episode_len":	200,
    "eps":	0.2,
    "eval_episodes":	10,
    "eval_num":	10,
    "gae":	0.95,
    "gamma":	0.99,
    "gpu_idx":	0,
    "group":	"03-17_18-07-09.837326-1769",
    "load_pretrained_model":	false,
    "log_intervals":	10,
    "logdir":	"log/train_log/03-17_18-07-09.837326-1769",
    "minibatch_size":	128,
    "name":	"ppo-car-1769-seed:8936",
    "num_minibatch":	10,
    "num_runs":	10,
    "project":	"Exp",
    "seed":	8936,
    "state_dim":	4,
    "target_kl":	0.02,
    "task":	"car",
    "timesteps":	15,
    "use_cuda":	true
}
PPO Training (Timesteps): 2560it [00:00, 3340.86it/s]                                                                                                                                                                                                                                                                                                                                               
Traceback (most recent call last):
  File "/home/minjae/research/RLCM/main.py", line 194, in <module>
    run(args, seed, unique_id, exp_time)
  File "/home/minjae/research/RLCM/main.py", line 174, in run
    trainer.train()
  File "/home/minjae/research/RLCM/trainer/online_trainer.py", line 97, in train
    eval_dict = self.evaulate()
                ^^^^^^^^^^^^^^^
  File "/home/minjae/research/RLCM/trainer/online_trainer.py", line 131, in evaulate
    a, _ = self.policy(obs, deterministic=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/minjae/miniconda3/envs/rlcm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/minjae/miniconda3/envs/rlcm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/minjae/research/RLCM/policy/ppo.py", line 74, in forward
    a, metaData = self.actor(obs, deterministic=deterministic)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/minjae/miniconda3/envs/rlcm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/minjae/miniconda3/envs/rlcm/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/minjae/research/RLCM/policy/layers/ppo_networks.py", line 62, in forward
    dist = MultivariateNormal(loc=mu, covariance_matrix=covariance_matrix)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/minjae/miniconda3/envs/rlcm/lib/python3.12/site-packages/torch/distributions/multivariate_normal.py", line 180, in __init__
    super().__init__(batch_shape, event_shape, validate_args=validate_args)
  File "/home/minjae/miniconda3/envs/rlcm/lib/python3.12/site-packages/torch/distributions/distribution.py", line 69, in __init__
    valid = constraint.check(value)
            ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/minjae/miniconda3/envs/rlcm/lib/python3.12/site-packages/torch/distributions/constraints.py", line 578, in check
    sym_check = super().check(value)
                ^^^^^^^^^^^^^^^^^^^^
  File "/home/minjae/miniconda3/envs/rlcm/lib/python3.12/site-packages/torch/distributions/constraints.py", line 555, in check
    if not square_check.all():
           ^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
